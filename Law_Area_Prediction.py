# -*- coding: utf-8 -*-
"""Progetto AI - Rocca_Sonia.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Tj6LzCMdyUuH712IpV4h_07aWdoRG0jm

**Task:**
L'obiettivo del progetto è la creazione di un text classificator in grado di predire, data una frase in input, l'area legale di appartenenza.

Le aree su cui il modello è stato allenato sono 3:


1.   Criminal
2.   Public
3.   Civil

Il dataset utilizzato, visualizzabile al seguente [link](https://huggingface.co/datasets/rcds/swiss_law_area_prediction), contiene degli estratti di sentenze della Corte Suprema svizzera, trascritte nelle tre lingue ufficiali dello Stato: tedesco, francese e italiano.
"""

!pip install datasets evaluate -U transformers[sentencepiece] #installazione librerie necessarie
!pip install accelerate -U

from datasets import load_dataset #per caricare il dataset da Hugging Face Hub
from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, DataCollatorWithPadding #per tokenizzare, creare modelli di classificazione e gestire il padding dei dati.
from sklearn.preprocessing import LabelEncoder #per convertire etichette di testo in numeri
from transformers import TrainingArguments, Trainer #per configurare e gestire il processo di addestramento del modello
import torch
import numpy as np #per operazioni matematiche e manipolazione di array
import evaluate

from huggingface_hub import notebook_login

notebook_login()

dataset_OG = load_dataset("rcds/swiss_law_area_prediction")

for split_name in dataset_OG.keys():
    dataset_OG[split_name] = dataset_OG[split_name].rename_column("law_area", "labels")
    dataset_OG[split_name] = dataset_OG[split_name].rename_column("facts", "text")

print("Il dataset è così composto:")
print(dataset_OG)

labels = {
    split: np.array(dataset_OG[split]['labels']) for split in dataset_OG
}

import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 3))
fig.suptitle('Bilanciamento dataset prima del downsampling:')

axes[0].hist(labels['train'], color = 'b')
axes[0].set_title('train')
axes[1].hist(labels['validation'], color = 'g')
axes[1].set_title('val')
axes[2].hist(labels['test'], color = 'y')
axes[2].set_title('test')

plt.tight_layout()
plt.show()

from datasets import DatasetDict, Dataset
import pandas as pd

#N campioni per etichetta nei diversi set
train_samples = 1000
validation_samples = 200
test_samples = 200

samples_dict = {
    'train': train_samples,
    'validation': validation_samples,
    'test': test_samples
}
downsampled_dataset = {}

for split_name, split_data in dataset_OG.items():
    subsplit_data_df = pd.DataFrame(split_data)

    downsampled_subset_data = pd.DataFrame(columns=subsplit_data_df.columns)

    #Downsampling per ogni etichetta
    for label in subsplit_data_df['labels'].unique():
        label_data = subsplit_data_df[subsplit_data_df['labels'] == label]
        downsampled_label_data = label_data.sample(min(len(label_data), samples_dict.get(split_name, len(label_data))))
        downsampled_subset_data = pd.concat([downsampled_subset_data, downsampled_label_data])

    downsampled_dataset[split_name] = Dataset.from_pandas(downsampled_subset_data)

downsampled_dict = DatasetDict(downsampled_dataset)

print("Contenuto dataset post downsampling:")
print(downsampled_dict)

labels = {
    split: np.array(downsampled_dict[split]['labels']) for split in downsampled_dict
}

import matplotlib.pyplot as plt

fig, axes = plt.subplots(1, 3, figsize=(15, 3))
fig.suptitle('Bilanciamento dataset post downsampling:')

axes[0].hist(labels['train'], color = 'b')
axes[0].set_title('train')
axes[1].hist(labels['validation'], color = 'g')
axes[1].set_title('val')
axes[2].hist(labels['test'], color = 'y')
axes[2].set_title('test')

plt.tight_layout()
plt.show()

from transformers import DistilBertTokenizer
checkpoint = "distilbert-base-multilingual-cased" #utilizzo un modello multilingua perchè il dataset contiene testi in francese,tedesco e italiano
tokenizer = DistilBertTokenizer.from_pretrained(checkpoint)

label_encoder = LabelEncoder() #conversione delle etichette da stringa a numero
label_encoder.fit(downsampled_dict["train"]["labels"])

def tokenize_function(examples):
    labels = label_encoder.transform(examples["labels"]) #prepara gli input del modello tokenizzando il testo e codificando le etichette
    tokenized_inputs = tokenizer(examples["text"], padding=True, truncation=True, return_tensors="pt")
    tokenized_inputs["labels"] = torch.tensor(labels, dtype=torch.long)

    return tokenized_inputs

class_mapping = label_encoder.classes_ #contiene le classi del problema di classificazione.
print("Class Mapping:", class_mapping)

id2label = {0: "Civil", 1: "Criminal", 2: "Public"} #utilizzati per creare una mappatura tra gli identificatori numerici e le etichette delle classi
label2id = {"Civil": 0, "Criminal":1, "Public": 2}

tokenized_dataset = downsampled_dict.map(tokenize_function, batched=True, remove_columns=["considerations", "language","court", "chamber", "region", "year", "decision_id","canton", "law_sub_area"]) #rimozione colonne non utili

from transformers import DataCollatorWithPadding #gestisce il padding delle sequenze in modo che tutte le sequenze in un batch abbiano la stessa lunghezza

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

from transformers import DistilBertForSequenceClassification
checkpoint = "distilbert-base-multilingual-cased"
model = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(label_encoder.classes_), id2label= id2label)
#Imposta il numero di etichette di classificazione, valore è ottenuto dalla lunghezza del set di etichette utilizzate

metric = evaluate.load("accuracy")
def compute_metrics(eval_pred):
    logits, labels = eval_pred #estrazione delle previsioni del modello (logits) e le etichette reali (labels) dal risultato della valutazione
    predictions = np.argmax(logits, axis=-1) #Calcolo l'indice della classe predetta con la probabilità massima per ciascuna istanza nel batch.
    return metric.compute(predictions=predictions, references=labels)

training_args = TrainingArguments(
    output_dir= "primo_modello",
    learning_rate=1e-5, #tasso di apprendimento che controlla la dimensione del passo nell'aggiornamento dei pesi durante l'addestramento
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    num_train_epochs=10,
    weight_decay=0.02, #termine di regolarizzazione che impedisce ai pesi del modello di diventare troppo grandi durante l'addestramento.
    do_eval=True,
    evaluation_strategy="steps",
    save_strategy="steps",
    eval_steps=500,
    logging_steps=10
)

trainer_1 = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer_1.train()

predictions_1 = trainer_1.predict(tokenized_dataset["test"]) #per ottenere le previsioni del modello sul dataset di test
print(predictions_1.predictions.shape, predictions_1.label_ids.shape)
real_labels = predictions_1.label_ids
preds_labels = np.argmax(predictions_1.predictions, axis=-1)

from sklearn.metrics import classification_report

report_1 = classification_report(real_labels, preds_labels)
print("Classification Report primo trainer.train:")
print(report_1)

metric = evaluate.load("accuracy")
metric.compute(predictions=preds_labels, references=real_labels)

"""Secondo allenamento:"""

from transformers import DistilBertForSequenceClassification
checkpoint = "distilbert-base-multilingual-cased"
model = DistilBertForSequenceClassification.from_pretrained(checkpoint, num_labels=len(label_encoder.classes_), id2label= id2label)

training_args = TrainingArguments(
    output_dir= "secondo_modello",
    learning_rate=2e-5, #aumentato rispetto al primo training_args
    per_device_train_batch_size=16, #aumentato rispetto al primo training_args
    per_device_eval_batch_size=16,
    num_train_epochs=10,
    weight_decay=0.01, #diminuito rispetto al primo training_args
    do_eval=True,
    evaluation_strategy="steps",
    save_strategy="steps",
    eval_steps=500,
    logging_steps=10,
)


trainer_2 = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["validation"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics,
)

trainer_2.train()

predictions_2 = trainer_2.predict(tokenized_dataset["test"])
print(predictions_2.predictions.shape, predictions_2.label_ids.shape)

true_labels_2 = predictions_2.label_ids
pred_labels_2 = np.argmax(predictions_2.predictions, axis=-1)
report_2 = classification_report(true_labels_2, pred_labels_2)
print("Classification Report secondo trainer.train:")
print(report_2)

metric = evaluate.load("accuracy") #calcolo accuracy sulle predizioni del secondo modello
metric.compute(predictions=pred_labels_2, references=true_labels_2)

"""Creazione tabelle con metriche relative ai due allenamenti:"""

import pandas as pd

primo_report = report_1.split('\n')
secondo_report = report_2.split('\n')

header = ['Model', 'Precision', 'Recall', 'F1-Score', 'Support']
data = []
accuracy_primo = 0.94
accuracy_secondo = 0.95

# Primo modello
model1_name = 'primo_modello:'
model1_values = [float(val) for val in primo_report[3].split()[1:5]]
data.append([model1_name] + model1_values)
print("Accuracy del primo_modello:", accuracy_primo)


# Secondo modello
model2_name = 'secondo_modello:'
model2_values = [float(val) for val in secondo_report[3].split()[1:5]]
data.append([model2_name] + model2_values)
print('Accuracy del secondo_modello:', accuracy_secondo)

df = pd.DataFrame(data, columns=header)
print(df)

"""Caricamento dei modelli su Hugging Face"""

trainer_1.push_to_hub()

trainer_2.push_to_hub()

"""Le tre frasi sotto riportate sono state estratte dal test set del dataset."""

criminal_text = "Die Täterschaft fuhr mit einem entwendeten Kleinlaster rückwärts in die Fensterscheibe des Geschäfts, aus welchem Uhren und Schmuck im Wert von über Fr. 80'000.-- gestohlen wurden. Es entstand ein Sachschaden von über Fr. 120'000.--. Am 27. Dezember 2002 wurde in einem Uhren- und Bijouteriegeschäft in Lenzerheide/GR ein weiterer Einbruchsdiebstahl verübt. Auch in diesem Fall wurde mit einem entwendeten Personenwagen die Schaufensterscheibe aufgebrochen. Aus dem Geschäft wurden Uhren und Schmuck im Wert von über Fr. 150'000.-- gestohlen. Am Gebäude und an Uhren entstand ein Sachschaden von über Fr. 300'000.--. Zwei unbeteiligte Passanten begaben sich, nachdem sie das Klirren und eine Alarmsirene gehört hatten, zum Tatort. Einer der Täter warf ihnen einen vier Kilogramm schweren Kreuzschlaghammer entgegen, ohne sie zu treffen."
civil_text = "En substance, les premiers juges ont admis que les travaux d'installation du magasin D_ avaient restreint l'usage de la chose louée pour la période allant du 1 er octobre 2010 au 31 janvier 2011. Ils n'ont, en revanche, retenu aucun défaut de la chose louée depuis l'ouverture du magasin D_ et ont débouté A_ de ses conclusions en réduction permanente de son loyer dès le 1 er février 2011. b. Par acte déposé le 18 novembre 2013 au greffe de la Cour de justice, A_ forme appel contre ce jugement dont il sollicite l'annulation. Il conclut à une réduction de son loyer de 40% pour la période du 1 er octobre 2010 au 31 janvier 2011 et à une réduction de son loyer de 35% dès le 1 er février 2011 en raison des nuisances liées à l'installation du magasin D_. Trois jours plus tard, il a produit à l'appui de ses écritures, une pièce nouvelle, à savoir la preuve du paiement de son loyer le 2 août 2013. c. Le 19 décembre 2013, la B_ conclut, principalement, au rejet de l'appel ainsi qu'au déboutement de A_ de toutes ses conclusions et forme un appel joint, sollicitant l'annulation du jugement et au déboutement de A_ de toutes ses conclusions"
public_text = "In ottemperanza alle norme vigenti sulla trasparenza e l'accesso alle informazioni pubbliche, l'ente pubblico rende pubblico il rapporto annuale sulle attività svolte nel corso dell'anno fiscale, affinché i cittadini possano esercitare il loro diritto di essere informati sull'operato dell'amministrazione pubblica."

from transformers import pipeline
classifier = pipeline("text-classification", model="primo_modello")

classifier(criminal_text)

classifier(civil_text)

classifier(public_text)

from transformers import pipeline
classifier = pipeline("text-classification", model="secondo_modello")

classifier(criminal_text)

classifier(civil_text)

classifier(public_text)

"""Creazione tabelle per allenamento: i report sono visualizzabili all'interno di file txt."""

from tabulate import tabulate
report_data = []
for line in report_1.split('\n'):
    row = line.split()
    if len(row) > 0:
        report_data.append(row)

table = tabulate(report_data[1:], headers=report_data[0], tablefmt='pretty')

primo_modello = "report_1.txt"
with open(primo_modello, "w") as file:
    file.write(table)

print(f"La tabella del report di classificazione del primo modello è pronta: il {primo_modello} è disponibile nella sezione file di Google Colab.")

report_data = []
for line in report_2.split('\n'):
    row = line.split()
    if len(row) > 0:
        report_data.append(row)

table = tabulate(report_data[1:], headers=report_data[0], tablefmt='pretty')

secondo_modello = "report_2.txt"
with open(secondo_modello, "w") as file:
    file.write(table)

print(f"La tabella del report di classificazione del secondo modello è pronta: il {secondo_modello} è disponibile nella sezione file di Google Colab.")